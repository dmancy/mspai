/*
    ======================================================================
    ======================================================================
    ==                                                                  ==
    ==  MSPAI:  Modified SPAI algorithm to comupte SParse Approximate   ==
    ==          Invers matrices.                                        ==
    ==                                                                  ==
    ==  Copyright (C)  2007, 2008, 2009 by                              ==
    ==                 Matous Sedlacek <sedlacek@in.tum.de>             ==
    ==                 Chair of Scientific Computing -- Informatics V   ==
    ==                 Technische Universität München                   ==
    ==                                                                  ==
    ==  This file is part of MSPAI.                                     ==
    ==                                                                  ==
    ==  MSPAI is free software: you can redistribute it and/or          ==
    ==  modify it under the terms of the GNU Lesser General Public      ==
    ==  License as published by the Free Software Foundation, either    ==
    ==  version 3 of the License, or (at your option) any later version.==
    ==                                                                  ==
    ==  MSPAI is distributed in the hope that it will be useful,        ==
    ==  but WITHOUT ANY WARRANTY; without even the implied warranty of  ==
    ==  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   ==
    ==  GNU Lesser General Public License for more details.             ==
    ==                                                                  ==
    ==  You should have received a copy of the GNU Lesser General       ==
    ==  Public License along with MSPAI.                                ==
    ==  If not, see <http://www.gnu.org/licenses/>.                     ==
    ==                                                                  ==
    ======================================================================
    ======================================================================
*/

#include "Block.h"

template <class T>
Matrix<T>::Matrix(MPI_Comm world_m)
{
    world = world_m;
    MPI_Comm_size(world, &num_procs);
    MPI_Comm_rank(world, &my_id);

    my_nbr_cols         = 0;
    my_start_idx        = 0;
    n                   = 0;
    m                   = 0;
    all_nbr_cols        = NULL;
    start_indices       = NULL;
    len_all_cols        = NULL;
    len_all_rows        = NULL;
    remote_col_idcs_buf = NULL;
    remote_row_idcs_buf = NULL;
    remote_col_buf      = NULL;
    my_nnz              = 0;
    pe                  = NULL;
    next_col            = 0;
    max_nnz             = 0;
    symmetric           = false;
    block_size          = 1;
    max_block_size      = 0;
    block_sizes         = NULL;
}



template <class T>
Matrix<T>::~Matrix()
{
    if (c_lines)
        delete c_lines;
    if (all_nbr_cols)           delete [] all_nbr_cols;
    if (start_indices)          delete [] start_indices;
    if (pe)                     delete [] pe;
    if (len_all_cols)           delete [] len_all_cols;
    if (len_all_rows)           delete [] len_all_rows;
    if (remote_col_buf)         delete [] remote_col_buf;
    if (remote_col_idcs_buf)    delete [] remote_col_idcs_buf;
    if (remote_row_idcs_buf)    delete [] remote_row_idcs_buf;
    if (block_sizes)            delete [] block_sizes;
}



template <class T>  int
Matrix<T>::Count_NNZ()
{
    int nnz = 0,
        my_nnz = 0;

    for ( int i = 0; i < my_nbr_cols; i++ )
        my_nnz += c_lines->len_cols[i];

    //Sum all nnz values
    MPI_Allreduce(&my_nnz, &nnz, 1,
                  MPI_INT, MPI_SUM, world);

    return nnz;
}



template <class T>  void
Matrix<T>::Init_Preconditioner(Matrix<T> *&M,
                               const int m_dim,
                               const int n_dim)
{
    M = new Matrix<T>(world);

    M->n = n_dim;
    M->m = m_dim;
    M->all_nbr_cols = new int[M->num_procs];
    M->start_indices = new int[M->num_procs];

    // Filling all_nbr_cols array
    MPI_Barrier(world);
    MPI_Allgather(static_cast<void *>(&my_nbr_cols), 1, MPI_INT,
                  static_cast<void *>(M->all_nbr_cols), 1, MPI_INT,
                  world);

    // Filling start indices array
    M->start_indices[0] = 0;
    for (int i = 1; i < M->num_procs; i++)
        M->start_indices[i] = M->start_indices[i-1] +
                              M->all_nbr_cols[i-1];

    M->my_nbr_cols = M->all_nbr_cols[M->my_id];
    M->my_start_idx = M->start_indices[M->my_id];
    M->c_lines = new Compressed_Lines<T>(M->my_nbr_cols,
                                         symmetric);

    // Filling pe array
    M->pe = new int[n];
    for (int i = 0; i < n; i++)
        M->pe[i] = pe[i];
}



template <class T> Pattern *
Matrix<T>::To_Pattern(Matrix<T> *mtx, const bool use_prob)
{
    MPI_Comm    world    = mtx->world;

    Pattern     *P       = NULL;

    Index_Set   *i_set   = NULL;

    int         len,
                curr_len,
                start_idx;

    P                = new Pattern(mtx->n, mtx->my_nbr_cols, world);
    P->all_nbr_cols  = new int[P->num_procs];
    P->start_indices = new int[P->num_procs];
    P->pe            = new int[mtx->n];

    MPI_Barrier(world);
    MPI_Allgather(static_cast<void *>(&my_nbr_cols), 1, MPI_INT,
                  static_cast<void *>(P->all_nbr_cols), 1, MPI_INT,
                                      world);

    // Filling start indices
    P->start_indices[0] = 0;
    for (int pe = 1; pe < P->num_procs; pe++)
        P->start_indices[pe] = P->start_indices[pe-1] +
                               P->all_nbr_cols[pe-1];

    // filling pe array
    memset(P->pe, 0, mtx->n * sizeof(int));
    for (int pe = 0; pe < P->num_procs; pe++)
    {
        start_idx = P->start_indices[pe];
        for (int i = 0; i < P->all_nbr_cols[pe]; i++)
            P->pe[start_idx + i] = pe;
    }

    P->my_nbr_cols = P->all_nbr_cols[P->my_id];
    P->my_start_idx = P->start_indices[P->my_id];

    // If probing and P(A) is used, than the
    // pattern from the additional probing
    // matrices have to be omitted.
    if (use_prob)
    {
        for (int col = 0; col < mtx->my_nbr_cols; col++)
        {
            curr_len = 0;
            len = mtx->c_lines->len_cols[col];

            for (int i = 0; i < len; i++)
            {
                if (mtx->c_lines->col_idcs[col][i] >= mtx->n)
                    break;
                curr_len++;
            }

            i_set = new Index_Set(curr_len);
            memcpy(i_set->idcs,
                   mtx->c_lines->col_idcs[col],
                   curr_len * sizeof(int));
            P->j_sets[col] = i_set;
        }
    }
    else
    {
        // Filling pattern data structure with indices
        for (int col = 0; col < mtx->my_nbr_cols; col++)
        {
            len = mtx->c_lines->len_cols[col];
            i_set = new Index_Set(len);
            memcpy(i_set->idcs,
                   mtx->c_lines->col_idcs[col],
                   len * sizeof(int));
            P->j_sets[col] = i_set;
        }
    }

    // Get the maximum number of nnz per
    // column/row of all pes
    MPI_Barrier(world);
    MPI_Allreduce(&mtx->max_nnz, &P->max_nnz, 1,
                  MPI_INT, MPI_MAX,
                  world);

    return P;
}


template <class T> Pattern *
Matrix<T>::To_Pattern_Powers(Matrix<double> *mtx, const int nb_pw, const bool use_prob)
{
    MPI_Comm    world    = mtx->world;

    Pattern     *P       = NULL;

    Index_Set   *i_set   = NULL;
    Matrix      *B       = NULL;

    int         len,
                curr_len,
                start_idx;
    
    Matrix <double> *C = NULL;
    Mat *C_petsc = NULL;
    PetscErrorCode ierr;
    MatInfo matinfo;
    PetscInt N, *List_lfill = NULL;
    double moy = 0;
    
    int sum = 0;

    List_lfill = new int[mtx->my_nbr_cols];

    for (int col = 0; col < mtx->my_nbr_cols; col++)
{
		List_lfill[col] = mtx->len_all_cols[my_start_idx + col];
		sum += List_lfill[col];
}
    
    mtx->Sparsify(&C, List_lfill);

    for (int k = 0; k < nb_pw; k++)
    {
	    if (k>=1)
		{
		    ierr = C->Convert_Mat_to_Matrix(world, &C, C_petsc);
	    	    C->Sparsify(&C, List_lfill);
		}

	    ierr = C->Convert_Matrix_to_Mat(world, C, &C_petsc);

    	    ierr = MatMatMult(*C_petsc, *C_petsc, MAT_INITIAL_MATRIX , PETSC_DEFAULT, C_petsc);	    

	
	MatGetInfo(*C_petsc,MAT_GLOBAL_SUM,&matinfo);
    }
	MatGetInfo(*C_petsc,MAT_GLOBAL_SUM,&matinfo);

	
    ierr = C->Convert_Mat_to_Matrix(world, &C, C_petsc);

    C->Sparsify(&C, List_lfill);

    ierr = Convert_Matrix_to_Mat(world, C, &C_petsc);


    P                = new Pattern(C->n, C->my_nbr_cols, world);
    P->all_nbr_cols  = new int[P->num_procs];
    P->start_indices = new int[P->num_procs];
    P->pe            = new int[C->n];

    MPI_Barrier(world);
    MPI_Allgather(static_cast<void *>(&my_nbr_cols), 1, MPI_INT,
                  static_cast<void *>(P->all_nbr_cols), 1, MPI_INT,
                                      world);

    // Filling start indices
    P->start_indices[0] = 0;
    for (int pe = 1; pe < P->num_procs; pe++)
        P->start_indices[pe] = P->start_indices[pe-1] +
                               P->all_nbr_cols[pe-1];

    // filling pe array
    memset(P->pe, 0, C->n * sizeof(int));
    for (int pe = 0; pe < P->num_procs; pe++)
    {
        start_idx = P->start_indices[pe];
        for (int i = 0; i < P->all_nbr_cols[pe]; i++)
            P->pe[start_idx + i] = pe;
    }

    P->my_nbr_cols = P->all_nbr_cols[P->my_id];
    // If probing and P(A) is used, than the
    // pattern from the additional probing
    // matrices have to be omitted.
    if (use_prob)
    {
        for (int col = 0; col < C->my_nbr_cols; col++)
        {
            curr_len = 0;
            len = C->c_lines->len_cols[col];

            for (int i = 0; i < len; i++)
            {
                if (C->c_lines->col_idcs[col][i] >= C->n)
                    break;
                curr_len++;
            }

            i_set = new Index_Set(curr_len);
            memcpy(i_set->idcs,
                   C->c_lines->col_idcs[col],
                   curr_len * sizeof(int));
            P->j_sets[col] = i_set;
        }
    }
    else
    {
        // Filling pattern data structure with indices
        for (int col = 0; col < C->my_nbr_cols; col++)
        {
            len = C->c_lines->len_cols[col];
            i_set = new Index_Set(len);
            memcpy(i_set->idcs,
                   C->c_lines->col_idcs[col],
                   len * sizeof(int));
            P->j_sets[col] = i_set;
        }
    }



    // Get the maximum number of nnz per
    // column/row of all pes
    MPI_Barrier(world);
    MPI_Allreduce(&C->max_nnz, &P->max_nnz, 1,
                  MPI_INT, MPI_MAX,
                  world);

    //P->Print_Pattern_Data();
    ierr = MatDestroy(C_petsc);
    delete C;
    delete [] List_lfill;

    return P;
}





template <class T> void 
Matrix<T>::Sparsify(Matrix<T> **Mat_pattern, const int *List_lfill)
{

    int rank, size;
    int           i,Ii, len_row, lfill, test_idx_diag, *cols_temp = 0, col_tmp;
	int my_local_nnz = 0, max = 0;
    double        val_diag = 0, *vals_temp = 0, val_tmp;
    Row_sparsify  *row_sparsify=0;
    Matrix        *C = NULL;
	int *nbr_idx_del_in = NULL, *nbr_idx_del_out = NULL; //Number of indexes deleted per row
	int gap = 0;
	int initialization = 0;

    MPI_Comm_size(world, &size);
    MPI_Comm_rank(world, &rank);

    if (!(*Mat_pattern))
	    initialization = 1;

    if (initialization)
    {	
	/*Initialization of the sparsified matrix */
	Init_Preconditioner(C, this->n, this->n);	

	C->c_lines->col_idcs_buf = new int[my_nnz];
	C->c_lines->col_buf = new T[my_nnz];
	C->len_all_cols = new int[n];
	C->len_all_rows = new int[n];
    }
    else
    {
	    C = *Mat_pattern;
    }


    /*Initialisation*/

    row_sparsify = new Row_sparsify[n];
    vals_temp = new double[n];
    cols_temp = new int[n];
    nbr_idx_del_in = new int[n];
    nbr_idx_del_out = new int[n];

    memset(nbr_idx_del_in, 0, n * sizeof(int));
    memset(nbr_idx_del_out, 0, n * sizeof(int));

    //Loop over the rows to Sparsify

    for (Ii = 0; Ii< my_nbr_cols; Ii++) 
    {

        val_diag = 0;
        // lfill = (int)moy*.2+2;
        lfill = List_lfill[Ii];
//	lfill = 2;
        len_row = std::min(lfill, c_lines->len_cols[Ii]);
        len_row = std::max(lfill, 1);
        test_idx_diag = 0;


        // prepare data to keep only the largest entries
        for (i=0; i<c_lines->len_cols[Ii]; i++)
        {
          row_sparsify[i].col = c_lines->col_idcs[Ii][i];
          row_sparsify[i].val = abs_complex(c_lines->A[Ii][i]);

          if (row_sparsify[i].col==Ii + C->my_start_idx)
              val_diag = row_sparsify[i].val;
        }

        // Retain the len_row largest entries in that row
        kLargest(row_sparsify, c_lines->len_cols[Ii], len_row);
	
//	if (Ii%1 == 0)
//	{
//				
//		for (i=0; i<len_row; i++)
//		{
//			printf(" Ii : %d, col: %d, val : %f\n", Ii, row_sparsify[i].col, row_sparsify[i].val);
//		}
//	}


        for (i=0; i<len_row; i++)
        {
          vals_temp[i] = row_sparsify[i].val;
          cols_temp[i] = row_sparsify[i].col;
          if (cols_temp[i]==Ii+C->my_start_idx)
              test_idx_diag=1;  //La diagonale a ete ajoutee
        }

        // the dagonal is added
        if (!test_idx_diag)
          {
		  if (len_row > 1)
		  {
			    val_tmp = vals_temp[len_row-2];
			    col_tmp = cols_temp[len_row-2];
			    vals_temp[len_row-2] = val_diag;
			    cols_temp[len_row-2] = Ii+C->my_start_idx;
			    vals_temp[len_row-1] = val_tmp;
			    cols_temp[len_row-1] = col_tmp;
		  }
		  else
		  {
			  vals_temp[0] = val_diag;
			  cols_temp[0] = Ii+C->my_start_idx;
		  }


            // len_row+=1;
          }

          i = len_row;

          /*Si plusieures entrees de la colonne sont egales, ont les ajoute quand meme.*/
          while((row_sparsify[i].val == row_sparsify[len_row-1].val) && (i<c_lines->len_cols[Ii]))
          {
	
            vals_temp[i] = row_sparsify[i].val;
            cols_temp[i] = row_sparsify[i].col;
            if (cols_temp[i]==Ii)
                test_idx_diag=1;
            len_row += 1;
            i+=1;
          }

	  /* On memorise les indices des lignes supprimees */

	  for (int k = len_row; k < c_lines->len_cols[Ii]; k++)
	{
		  nbr_idx_del_in[row_sparsify[k].col] += 1;
	}

	  
	

          C->c_lines->len_cols[Ii] = len_row;

	  /* Set up compressed lines of C */

/*	  if (initialization)
	  {
		  C->c_lines->A[Ii] = new T[len_row];
		  C->c_lines->col_idcs[Ii] = new int[len_row]; 
	  }
*/

	/* Set up the column structure */

          memcpy(&(C->c_lines->col_idcs_buf[gap]), cols_temp, len_row*sizeof(int));
          memcpy(&(C->c_lines->col_buf[gap]), vals_temp, len_row * sizeof(T));
	 
	  C->c_lines->A[Ii] = &(C->c_lines->col_buf[gap]);
	  C->c_lines->col_idcs[Ii] = &(C->c_lines->col_idcs_buf[gap]);
	


	  gap += len_row;


	  my_local_nnz += len_row;
          }

          delete [] row_sparsify;

          delete [] vals_temp;
          delete [] cols_temp;



	
    	/* Update matrix caracteristics */
    	C->my_nnz = my_local_nnz;

	/*Get length of all columns */
	MPI_Barrier(world);
	MPI_Allgatherv( static_cast<void *>(C->c_lines->len_cols), 
                        C->my_nbr_cols, MPI_INT,
	                static_cast<void *>(C->len_all_cols), 
		        C->all_nbr_cols, C->start_indices, 
		        MPI_INT, world);


	/*Get length of all rows */	
	MPI_Barrier(world);
        MPI_Allreduce(nbr_idx_del_in, nbr_idx_del_out, n,
                      MPI_INT, MPI_SUM,
                      world);

	for (int k = 0; k < n; k++)
		C->len_all_rows[k] = len_all_rows[k] - nbr_idx_del_out[k];
	
	for (int k = 0; k < my_nbr_cols; k++)
		C->c_lines->len_rows[k] = C->len_all_rows[C->my_start_idx + k];


	/* Get the maximum number of nnz per column/row of all pes */
	/*
	for (i = 0; i < mtx->my_nbr_cols; i++)
		if (mtx->c_lines->len_rows[i] > max)
			max = mtx->c_lines->len_rows[i];

	for (i=0; i< mtx->my_nbr_cols; i++)
		if (mtx->c_lines->len_cols[i] > max)
			max = mtx->c_lines->len_cols[i];

	MPI_Barrier(mtx->world);
	MPI_Allreduce(&max, &mtx->max_nnz, 1, MPI_INT, MPI_MAX, mtx->world);
	*/

	for (i=0; i < n; i++)
	{
		if (C->len_all_rows[i] > max)
			max = C->len_all_rows[i];
		if (C->len_all_cols[i] > max)
			max = C->len_all_cols[i];
	}

	C->max_nnz = max;



	delete nbr_idx_del_in;
	delete nbr_idx_del_out;

	if (initialization)
		*Mat_pattern = C;

}



template <class T> PetscErrorCode
Matrix<T>::Convert_Matrix_to_Mat(MPI_Comm comm, Matrix<double> *B, Mat **PB)
	{
		PetscMPIInt	siz, rank;
		PetscErrorCode	ierr;
		int            m,n,M,N;
		int            d_nz,o_nz;
		int            *d_nnz,*o_nnz;
		int            i,k,global_row,global_col,first_diag_col,last_diag_col;
		PetscScalar    val;
		Mat* MP = NULL;
		
		PetscFunctionBegin;
		ierr = MPI_Comm_size(comm, &siz);
		ierr = MPI_Comm_rank(comm, &rank);
		
		if (*PB)
			MatDestroy(*PB);

		m = n = B->all_nbr_cols[rank];
		d_nz = o_nz = 0;

		/* Determine preallocation for MatCreateMPIAIJ */
		ierr = PetscMalloc1(m, &d_nnz);
		ierr = PetscMalloc1(m, &o_nnz);
		MP = new Mat;


		for (i=0; i<m; i++)
			d_nnz[i] = o_nnz[i] = 0;
		first_diag_col = B->my_start_idx;
		last_diag_col = first_diag_col + B->my_nbr_cols;
		
		for (i=0; i<B->all_nbr_cols[rank]; i++)
		{
			for (k=0; k<B->c_lines->len_cols[i]; k++){
				global_col = B->c_lines->col_idcs[i][k];
				if ((global_col >= first_diag_col) & (global_col < last_diag_col))
					d_nnz[i]++;
				else
					o_nnz[i]++;
			}
		}

		M = N = B->n;

		/* Here we only know how to create AIJ format */
		ierr = MatCreate(comm,MP);CHKERRQ(ierr);
		ierr = MatSetSizes(*MP,m,n,M,N);CHKERRQ(ierr);
		ierr = MatSetType(*MP,MATAIJ);CHKERRQ(ierr);
		ierr = MatSeqAIJSetPreallocation(*MP,d_nz,d_nnz);CHKERRQ(ierr);
		ierr = MatMPIAIJSetPreallocation(*MP,d_nz,d_nnz,o_nz,o_nnz);CHKERRQ(ierr);
		

		for (i=0; i<B->my_nbr_cols; i++)
		{
			global_row = B->my_start_idx+i;
			for (k=0; k<B->c_lines->len_cols[i]; k++)
			{
				global_col = B->c_lines->col_idcs[i][k];

				val = abs_complex(B->c_lines->A[i][k]);
				ierr = MatSetValues(*MP,1,&global_row,1,&global_col,&val,ADD_VALUES);
			}
		}

		ierr = PetscFree(d_nnz);
		ierr = PetscFree(o_nnz);

		ierr = MatAssemblyBegin(*MP, MAT_FINAL_ASSEMBLY);
		ierr = MatAssemblyEnd(*MP, MAT_FINAL_ASSEMBLY);
		*PB = MP;
		PetscFunctionReturn(0);
	}

		
template <class T> 
PetscErrorCode Matrix<T>::Convert_Mat_to_Matrix(MPI_Comm comm, Matrix<double> **B, Mat *A)
{
	Matrix<double>               *M = NULL;
	Mat			AT;
	int                     i,j;
	int                     row_indx;
	int                     len,pe,start_indx;
	int 			A_buf_size = 0;
	int 			row_buf_size = 0;
	PetscErrorCode          ierr;
  const int               *cols = NULL;
	const double            *vals = NULL;
	int                     n,m,mnl,nnl,nz,rstart,rend,gap = 0, max = 0;
	PetscMPIInt             size,rank;
	PetscBool 		isSymmetric;
	Compressed_Lines<double> *lines = NULL;
	MatInfo                 matinfo;
	
	PetscFunctionBegin;
	ierr = MPI_Comm_size(comm,&size);CHKERRQ(ierr);
	ierr = MPI_Comm_rank(comm,&rank);CHKERRQ(ierr);
	ierr = MatGetSize(*A,&m,&n);CHKERRQ(ierr);
	ierr = MatGetLocalSize(*A,&mnl,&nnl);CHKERRQ(ierr);


	M = new Matrix<double>(comm);

	M->n = n;
	M->m = m;

	M->all_nbr_cols  = new int[M->num_procs];
	M->start_indices = new int[M->num_procs];
        M->pe		 = new int[n];

	//Use the transpose to get the row non zero structure
	ierr = MatTranspose(*A, MAT_INITIAL_MATRIX, &AT);CHKERRQ(ierr);


	MPI_Barrier(comm);
	ierr = MPI_Allgather(static_cast<void *>(&mnl), 1, MPI_INT, static_cast<void *>(M->all_nbr_cols), 1, MPI_INT, comm);CHKERRQ(ierr);

	/* Filling start indices */
	M->start_indices[0] = 0;
	for (int pe = 1; pe < M->num_procs; pe++)
	{
		M->start_indices[pe] = M->start_indices[pe-1] + M->all_nbr_cols[pe-1];
	}


	/* Filling pe array */
	memset(M->pe, 0, n*sizeof(int));
	for (pe = 1; pe < M->num_procs; pe++)
	{
		start_indx = M->start_indices[pe];
		for (int k = 0; k < M->all_nbr_cols[pe]; k++)
		{
		       M->pe[start_indx + k] = pe;
		}
	}	
	
	ierr = MatEqual(*A, AT, &isSymmetric);CHKERRQ(ierr);
			

	if (isSymmetric)
		M->symmetric = true;

	M->my_nbr_cols = M->all_nbr_cols[M->my_id];
	M->my_start_idx = M->start_indices[M->my_id];

	/*number of nonzeros in each row */
	ierr = MatGetInfo(*A, MAT_GLOBAL_SUM, &matinfo);CHKERRQ(ierr);



	/*Number of nonzeros in each local rows*/
	ierr = MatGetInfo(*A, MAT_LOCAL, &matinfo);CHKERRQ(ierr);
	A_buf_size = matinfo.nz_used;
	M->my_nnz = matinfo.nz_used;
	
	M->c_lines = new Compressed_Lines<double>(M->my_nbr_cols, isSymmetric);

	/* Allocation of Compressed Lines */
  	lines = M->c_lines;
	lines->col_buf = new double[A_buf_size];
	lines->col_idcs_buf = new int[A_buf_size];
	


	/*Set colums and fill compressed lines*/

	for (int col=0; col < M->my_nbr_cols; col++)
	{
		ierr = MatGetRow(*A, col+M->my_start_idx, &nz, &cols, &vals);
		lines->len_cols[col] = nz;
		lines->A[col] = &(lines->col_buf[gap]);
		lines->col_idcs[col] = &(lines->col_idcs_buf[gap]);
		gap += nz;

		for (j=0; j<nz; j++)
		{
			lines->col_idcs[col][j]   = cols[j]; 
			lines->A[col][j]           = abs_complex(vals[j]);
		}
	
		ierr = MatRestoreRow(*A, col+M->my_start_idx, &nz, &cols, &vals);
	}


	/* Set up the row structure */

	if (!isSymmetric)
	{

		ierr = MatGetInfo(AT, MAT_LOCAL, &matinfo);CHKERRQ(ierr);
		row_buf_size = matinfo.nz_used;

		lines->row_idcs_buf = new int[row_buf_size];


		for (int row=0, gap = 0; row < M->my_nbr_cols; row++)
		{
			ierr = MatGetRow(AT, row+M->my_start_idx, &nz, &cols, NULL);
			lines->len_rows[row] = nz;
			lines->row_idcs[row] = &(lines->row_idcs_buf[gap]);
			gap += nz;

			for (int r = 0; r < nz; r++)
				lines->row_idcs[row][r] = cols[r];
			
			ierr = MatRestoreRow(AT, row+M->my_start_idx, &nz, &cols, NULL);
		}
	}


	/* Get length of all cols*/
	M->len_all_cols = new int[M->n];
	MPI_Barrier(comm);
	MPI_Allgatherv(static_cast<void *>(lines->len_cols), 
	               M->my_nbr_cols, MPI_INT,
	               static_cast<void *>(M->len_all_cols), 
	               M->all_nbr_cols, M->start_indices, 
	               MPI_INT, comm);
	
	/* Get length of all rows */
	M->len_all_rows = new int[M->n];
	MPI_Barrier(comm);
	MPI_Allgatherv(static_cast<void *>(lines->len_rows), 
                    M->my_nbr_cols, MPI_INT,
                    static_cast<void *>(M->len_all_rows), 
                    M->all_nbr_cols, M->start_indices, 
                    MPI_INT, comm);



	/* Get the maximum number of nnz per column/row of all pes */
	for (i = 0; i < M->my_nbr_cols; i++)
		if (lines->len_rows[i] > max)
			max = lines->len_rows[i];

	for (i=0; i< M->my_nbr_cols; i++)
		if (lines->len_cols[i] > max)
			max = lines->len_cols[i];

	MPI_Barrier(comm);
	MPI_Allreduce(&max, &M->max_nnz, 1, MPI_INT, MPI_MAX, comm);


	/* Initialize the remote transfer buffer */
	M->remote_col_buf = new double[M->max_nnz];
	memset(M->remote_col_buf, 0, M->max_nnz * sizeof(double));

	M->remote_col_idcs_buf = new int[M->max_nnz];
	memset(M->remote_col_idcs_buf, 0, M->max_nnz * sizeof(int));

	M->remote_row_idcs_buf = new int[M->max_nnz];
	memset(M->remote_row_idcs_buf, 0, M->max_nnz * sizeof(int));
		
  lines = NULL;

  delete *B;
	*B = M;

	ierr = MatDestroy(&AT);
	return ierr;

}	


template <class T> 
PetscErrorCode Matrix<T>::Convert_Mat_to_Matrix(MPI_Comm comm, Matrix<double> **B, Mat *A, Vec **prob_Ce, int prob_Ce_N)
{
/*
	Matrix<double>               *M = NULL;
	Mat			AT;
	int                     i,j;
	int                     row_indx;
	int                     len,pe,start_indx;
	int 			A_buf_size = 0;
	int 			row_buf_size = 0;
*/
	PetscErrorCode          ierr;
/*
	const int               *cols = NULL;
	const double            *vals = NULL;
	int                     n,m,mnl,nnl,nz,rstart,rend,gap = 0, max = 0;
	PetscMPIInt             size,rank;
	PetscBool 		isSymmetric;
	Compressed_Lines<double> *lines = NULL;
	MatInfo                 matinfo;


	PetscScalar 		**array;
	PetscFunctionBegin;
	ierr = MPI_Comm_size(comm,&size);CHKERRQ(ierr);
	ierr = MPI_Comm_rank(comm,&rank);CHKERRQ(ierr);
	ierr = MatGetSize(*A,&n,&n);CHKERRQ(ierr);
	ierr = MatGetLocalSize(*A,&mnl,&nnl);CHKERRQ(ierr);


	M = new Matrix<double>(comm);

	M->n = n;
	M->m = m;
	M->all_nbr_cols  = new int[M->num_procs];
	M->start_indices = new int[M->num_procs];
        M->pe		 = new int[n];

	//Use the transpose to get the row non zero structure
	ierr = MatTranspose(*A, MAT_INITIAL_MATRIX, &AT);CHKERRQ(ierr);


	MPI_Barrier(comm);
	ierr = MPI_Allgather(static_cast<void *>(&mnl), 1, MPI_INT, static_cast<void *>(M->all_nbr_cols), 1, MPI_INT, comm);CHKERRQ(ierr);
*/

	/* Filling start indices */
/*
	M->start_indices[0] = 0;
	for (int pe = 1; pe < M->num_procs; pe++)
	{
		M->start_indices[pe] = M->start_indices[pe-1] + M->all_nbr_cols[pe-1];
	}
*/

	/* Filling pe array */
/*
	memset(M->pe, 0, n*sizeof(int));
	for (pe = 1; pe < M->num_procs; pe++)
	{
		start_indx = M->start_indices[pe];
		for (int k = 0; k < M->all_nbr_cols[pe]; k++)
		{
		       M->pe[start_indx + k] = pe;
		}
	}	
	
	ierr = MatEqual(*A, AT, &isSymmetric);CHKERRQ(ierr);
			

	if (isSymmetric)
		M->symmetric = true;

	M->my_nbr_cols = M->all_nbr_cols[M->my_id];
	M->my_start_idx = M->start_indices[M->my_id];
*/
	/*number of nonzeros in each row */
/*
	ierr = MatGetInfo(*A, MAT_GLOBAL_SUM, &matinfo);CHKERRQ(ierr);
*/

	/*Number of nonzeros in each local rows*/
/*
	ierr = MatGetInfo(*A, MAT_LOCAL, &matinfo);CHKERRQ(ierr);
	A_buf_size = matinfo.nz_used;

	
	array = new PetscScalar*[prob_Ce_N];
*/
	
	/*Initialisation du tableau array*/
/*
	for (i=0; i<prob_Ce_N; i++)
	{
		  ierr = VecGetArray(*(prob_Ce[i]),&(array[i]));CHKERRQ(ierr);
	}

	for (i=0; i<prob_Ce_N; i++)
	{
		for (j=0; j<M->my_nbr_cols; j++)
		{
			if (array[i][j]!=0)
				A_buf_size++;
		}
	}
	
	M->my_nnz = A_buf_size;
	
	M->c_lines = new Compressed_Lines<double>(M->my_nbr_cols, isSymmetric);

*/
	/* Allocation of Compressed Lines */
/*
  	lines = M->c_lines;
	lines->col_buf = new double[A_buf_size];
	lines->col_idcs_buf = new int[A_buf_size];
	

*/
	/*Set colums and fill compressed lines*/
/*

	for (int col=0; col < M->my_nbr_cols; col++)
	{
		ierr = MatGetRow(*A, col+M->my_start_idx, &nz, &cols, &vals);
		lines->len_cols[col] = nz;
		lines->A[col] = &(lines->col_buf[gap]);
		lines->col_idcs[col] = &(lines->col_idcs_buf[gap]);
		gap += nz;

		for (j=0; j<nz; j++)
		{
			lines->col_idcs[col][j]   = cols[j]; 
			lines->A[col][j]           = abs_complex(vals[j]);
		}

		for (j=0; j<prob_Ce_N; j++)
		{
			if (array[j][col] != 0)
			{
				lines->col_idcs[col][nz+j]   = M->n + j; 
				lines->A[col][nz+j]          = array[j][col];
			}
				
		}
		ierr = MatRestoreRow(*A, col+M->my_start_idx, &nz, &cols, &vals);
	}

*/
	/* Set up the row structure */

/*
	if (!isSymmetric)
	{

		ierr = MatGetInfo(AT, MAT_LOCAL, &matinfo);CHKERRQ(ierr);
		row_buf_size = matinfo.nz_used;

		lines->row_idcs_buf = new int[row_buf_size];


		for (int row=0, gap = 0; row < M->my_nbr_cols; row++)
		{
			ierr = MatGetRow(AT, row+M->my_start_idx, &nz, &cols, NULL);
			lines->len_rows[row] = nz;
			lines->row_idcs[row] = &(lines->row_idcs_buf[gap]);
			gap += nz;

			for (int r = 0; r < nz; r++)
				lines->row_idcs[row][r] = cols[r];
			
			ierr = MatRestoreRow(AT, row+M->my_start_idx, &nz, &cols, NULL);
		}
	}

*/
	/* Get length of all cols*/
/*
	M->len_all_cols = new int[M->n];
	MPI_Barrier(comm);
	MPI_Allgatherv(static_cast<void *>(lines->len_cols), 
	               M->my_nbr_cols, MPI_INT,
	               static_cast<void *>(M->len_all_cols), 
	               M->all_nbr_cols, M->start_indices, 
	               MPI_INT, comm);
	*/
	/* Get length of all rows */
/*
	M->len_all_rows = new int[M->n];
	MPI_Barrier(comm);
	MPI_Allgatherv(static_cast<void *>(lines->len_rows), 
                    M->my_nbr_cols, MPI_INT,
                    static_cast<void *>(M->len_all_rows), 
                    M->all_nbr_cols, M->start_indices, 
                    MPI_INT, comm);


*/
	/* Get the maximum number of nnz per column/row of all pes */
/*
	for (i = 0; i < M->my_nbr_cols; i++)
		if (lines->len_rows[i] > max)
			max = lines->len_rows[i];

	for (i=0; i< M->my_nbr_cols; i++)
		if (lines->len_cols[i] > max)
			max = lines->len_cols[i];

	MPI_Barrier(comm);
	MPI_Allreduce(&max, &M->max_nnz, 1, MPI_INT, MPI_MAX, comm);
*/

	/* Initialize the remote transfer buffer */
/*
	M->remote_col_buf = new double[M->max_nnz];
	memset(M->remote_col_buf, 0, M->max_nnz * sizeof(double));

	M->remote_col_idcs_buf = new int[M->max_nnz];
	memset(M->remote_col_idcs_buf, 0, M->max_nnz * sizeof(int));

	M->remote_row_idcs_buf = new int[M->max_nnz];
	memset(M->remote_row_idcs_buf, 0, M->max_nnz * sizeof(int));
		

	*B = M;

	for (i=0; i<prob_Ce_N; i++)
	{
		ierr = VecRestoreArray(*(prob_Ce[i]),&(array[i]));CHKERRQ(ierr);	
	}

	delete array;

	ierr = MatDestroy(&AT);
*/
	return ierr;

}	



template <class T> 
Matrix<T>* Matrix<T>::Convert_Block_Matrix(Matrix<T> *A, int bs, int upper_bs_limit, int verbose)
{
    Matrix<T>* B;

    if (bs)
      B = Constant_Block_Matrix(A,bs);
    /*
    else
      B = Variable_Block_Matrix(A,upper_bs_limit);
    */

    return (B);
}

template <class T> 
Matrix<T>* Matrix<T>::Constant_Block_Matrix(Matrix<T> *A, int bs)
{
    Matrix<T> *V;
    int nblocks, *block_sizes;

    Find_Constant_Blocks(A, bs, block_sizes, nblocks);
    V = Convert_To_Block_Matrix(A, nblocks, block_sizes);

    V->block_size = bs;

    delete [] block_sizes;

    return V;
}

template <class T> 
void Matrix<T>::Find_Constant_Blocks(Matrix<T> *A, int block_size, int* &block_sizes, int& nblocks)
{
    int odd_block;

    nblocks = (A->my_nbr_cols)/block_size; 
    odd_block = (A->my_nbr_cols) % block_size;

    if (odd_block)
      nblocks++;

    block_sizes = new int[nblocks];

    for (int i=0; i<nblocks; i++)
      block_sizes[i] = block_size;

    if (odd_block)
      block_sizes[nblocks-1] = odd_block;

}



inline int comp (const void * elem1, const void * elem2)
{
	    const Row_sparsify *f = (Row_sparsify *) elem1;
	    const Row_sparsify *s = (Row_sparsify *) elem2;
	    return fabs(f->val) > fabs(s->val) ? -1 : fabs(f->val) < fabs(s->val);
	    return 0;
}

inline void kLargest(Row_sparsify  arr[], int n, int k)
{
	    qsort (arr, n, sizeof(arr[0]), comp);
}

